{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 100000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 1.5706408023834229,
      "learning_rate": 0.00029940299999999995,
      "loss": 3.5589,
      "step": 200
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.6357755661010742,
      "learning_rate": 0.00029880299999999994,
      "loss": 2.4541,
      "step": 400
    },
    {
      "epoch": 0.012,
      "grad_norm": 1.404890775680542,
      "learning_rate": 0.000298203,
      "loss": 2.2875,
      "step": 600
    },
    {
      "epoch": 0.016,
      "grad_norm": 1.0410438776016235,
      "learning_rate": 0.00029760299999999996,
      "loss": 2.1004,
      "step": 800
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2074344158172607,
      "learning_rate": 0.00029700299999999995,
      "loss": 2.0375,
      "step": 1000
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.8524104952812195,
      "learning_rate": 0.000296403,
      "loss": 2.0791,
      "step": 1200
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.8174076676368713,
      "learning_rate": 0.000295803,
      "loss": 1.9282,
      "step": 1400
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.9889084100723267,
      "learning_rate": 0.000295203,
      "loss": 1.9161,
      "step": 1600
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.716018795967102,
      "learning_rate": 0.000294603,
      "loss": 1.8895,
      "step": 1800
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.680820345878601,
      "learning_rate": 0.000294003,
      "loss": 1.9014,
      "step": 2000
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.841759979724884,
      "learning_rate": 0.00029340299999999997,
      "loss": 1.846,
      "step": 2200
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.0915441513061523,
      "learning_rate": 0.000292803,
      "loss": 1.7948,
      "step": 2400
    },
    {
      "epoch": 0.052,
      "grad_norm": 1.0093662738800049,
      "learning_rate": 0.000292203,
      "loss": 1.7749,
      "step": 2600
    },
    {
      "epoch": 0.056,
      "grad_norm": 1.1093701124191284,
      "learning_rate": 0.000291603,
      "loss": 1.8196,
      "step": 2800
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7262741923332214,
      "learning_rate": 0.00029100299999999996,
      "loss": 1.7289,
      "step": 3000
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.8504630923271179,
      "learning_rate": 0.000290403,
      "loss": 1.6853,
      "step": 3200
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.5904035568237305,
      "learning_rate": 0.000289803,
      "loss": 1.7033,
      "step": 3400
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.6939531564712524,
      "learning_rate": 0.000289203,
      "loss": 1.6577,
      "step": 3600
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.5995786190032959,
      "learning_rate": 0.00028860299999999996,
      "loss": 1.6758,
      "step": 3800
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0833278894424438,
      "learning_rate": 0.000288003,
      "loss": 1.6269,
      "step": 4000
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.9919660091400146,
      "learning_rate": 0.000287403,
      "loss": 1.6263,
      "step": 4200
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.5686782598495483,
      "learning_rate": 0.00028680299999999997,
      "loss": 1.575,
      "step": 4400
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.8514082431793213,
      "learning_rate": 0.00028620299999999996,
      "loss": 1.6125,
      "step": 4600
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.7794447541236877,
      "learning_rate": 0.000285603,
      "loss": 1.6147,
      "step": 4800
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4218732714653015,
      "learning_rate": 0.000285003,
      "loss": 1.5283,
      "step": 5000
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.7020696997642517,
      "learning_rate": 0.00028440299999999997,
      "loss": 1.4972,
      "step": 5200
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.731224775314331,
      "learning_rate": 0.000283803,
      "loss": 1.5755,
      "step": 5400
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.9789614081382751,
      "learning_rate": 0.000283203,
      "loss": 1.501,
      "step": 5600
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.552493155002594,
      "learning_rate": 0.000282603,
      "loss": 1.4691,
      "step": 5800
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5668216347694397,
      "learning_rate": 0.00028200299999999996,
      "loss": 1.4554,
      "step": 6000
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.8807042241096497,
      "learning_rate": 0.000281403,
      "loss": 1.5331,
      "step": 6200
    },
    {
      "epoch": 0.128,
      "grad_norm": 1.048603892326355,
      "learning_rate": 0.000280803,
      "loss": 1.425,
      "step": 6400
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.6410442590713501,
      "learning_rate": 0.000280203,
      "loss": 1.5059,
      "step": 6600
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.7467367053031921,
      "learning_rate": 0.00027960299999999996,
      "loss": 1.4222,
      "step": 6800
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7897689342498779,
      "learning_rate": 0.000279003,
      "loss": 1.4391,
      "step": 7000
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.6716380715370178,
      "learning_rate": 0.000278403,
      "loss": 1.4364,
      "step": 7200
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.9055171608924866,
      "learning_rate": 0.00027780299999999997,
      "loss": 1.3978,
      "step": 7400
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.8604981899261475,
      "learning_rate": 0.00027720299999999995,
      "loss": 1.4535,
      "step": 7600
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.6097655892372131,
      "learning_rate": 0.000276603,
      "loss": 1.4171,
      "step": 7800
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9986950755119324,
      "learning_rate": 0.000276003,
      "loss": 1.4497,
      "step": 8000
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.8431787490844727,
      "learning_rate": 0.00027540299999999997,
      "loss": 1.4549,
      "step": 8200
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.6968077421188354,
      "learning_rate": 0.00027480299999999995,
      "loss": 1.3379,
      "step": 8400
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.6404667496681213,
      "learning_rate": 0.000274203,
      "loss": 1.388,
      "step": 8600
    },
    {
      "epoch": 0.176,
      "grad_norm": 1.0215215682983398,
      "learning_rate": 0.000273603,
      "loss": 1.3581,
      "step": 8800
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.3038743734359741,
      "learning_rate": 0.00027300299999999996,
      "loss": 1.3626,
      "step": 9000
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.8416328430175781,
      "learning_rate": 0.00027240299999999995,
      "loss": 1.3464,
      "step": 9200
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.694053053855896,
      "learning_rate": 0.000271803,
      "loss": 1.3452,
      "step": 9400
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.8156750798225403,
      "learning_rate": 0.00027120299999999997,
      "loss": 1.3454,
      "step": 9600
    },
    {
      "epoch": 0.196,
      "grad_norm": 1.5501514673233032,
      "learning_rate": 0.00027060299999999996,
      "loss": 1.3215,
      "step": 9800
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6571704745292664,
      "learning_rate": 0.00027000299999999994,
      "loss": 1.2935,
      "step": 10000
    },
    {
      "epoch": 0.204,
      "grad_norm": 1.9045801162719727,
      "learning_rate": 0.000269403,
      "loss": 1.3519,
      "step": 10200
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.7849118709564209,
      "learning_rate": 0.00026880299999999997,
      "loss": 1.3081,
      "step": 10400
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.6675447225570679,
      "learning_rate": 0.00026820299999999995,
      "loss": 1.2746,
      "step": 10600
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.6002494692802429,
      "learning_rate": 0.000267603,
      "loss": 1.3385,
      "step": 10800
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6469331979751587,
      "learning_rate": 0.000267003,
      "loss": 1.2725,
      "step": 11000
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.9011368155479431,
      "learning_rate": 0.00026640299999999996,
      "loss": 1.2856,
      "step": 11200
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.5428163409233093,
      "learning_rate": 0.00026580299999999995,
      "loss": 1.2926,
      "step": 11400
    },
    {
      "epoch": 0.232,
      "grad_norm": 1.2948938608169556,
      "learning_rate": 0.000265203,
      "loss": 1.2281,
      "step": 11600
    },
    {
      "epoch": 0.236,
      "grad_norm": 1.6624702215194702,
      "learning_rate": 0.000264603,
      "loss": 1.3187,
      "step": 11800
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9227383136749268,
      "learning_rate": 0.00026400299999999996,
      "loss": 1.2389,
      "step": 12000
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.8845693469047546,
      "learning_rate": 0.00026340299999999994,
      "loss": 1.2703,
      "step": 12200
    },
    {
      "epoch": 0.248,
      "grad_norm": 1.3885200023651123,
      "learning_rate": 0.000262803,
      "loss": 1.2756,
      "step": 12400
    },
    {
      "epoch": 0.252,
      "grad_norm": 1.2408446073532104,
      "learning_rate": 0.00026220299999999997,
      "loss": 1.2446,
      "step": 12600
    },
    {
      "epoch": 0.256,
      "grad_norm": 2.347949743270874,
      "learning_rate": 0.00026160299999999995,
      "loss": 1.342,
      "step": 12800
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9203372597694397,
      "learning_rate": 0.00026100299999999994,
      "loss": 1.2381,
      "step": 13000
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.7692549824714661,
      "learning_rate": 0.000260403,
      "loss": 1.2764,
      "step": 13200
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.7937576174736023,
      "learning_rate": 0.00025980299999999997,
      "loss": 1.193,
      "step": 13400
    },
    {
      "epoch": 0.272,
      "grad_norm": 1.0301117897033691,
      "learning_rate": 0.00025920299999999995,
      "loss": 1.2946,
      "step": 13600
    },
    {
      "epoch": 0.276,
      "grad_norm": 1.0019831657409668,
      "learning_rate": 0.000258603,
      "loss": 1.2279,
      "step": 13800
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6911270618438721,
      "learning_rate": 0.000258003,
      "loss": 1.2203,
      "step": 14000
    },
    {
      "epoch": 0.284,
      "grad_norm": 1.0297729969024658,
      "learning_rate": 0.000257403,
      "loss": 1.2501,
      "step": 14200
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.8848400712013245,
      "learning_rate": 0.000256803,
      "loss": 1.2061,
      "step": 14400
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.6475992202758789,
      "learning_rate": 0.000256203,
      "loss": 1.2009,
      "step": 14600
    },
    {
      "epoch": 0.296,
      "grad_norm": 1.1439940929412842,
      "learning_rate": 0.00025560299999999997,
      "loss": 1.2004,
      "step": 14800
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.0591294765472412,
      "learning_rate": 0.000255003,
      "loss": 1.2213,
      "step": 15000
    },
    {
      "epoch": 0.304,
      "grad_norm": 1.0057793855667114,
      "learning_rate": 0.000254403,
      "loss": 1.2141,
      "step": 15200
    },
    {
      "epoch": 0.308,
      "grad_norm": 1.1588878631591797,
      "learning_rate": 0.000253803,
      "loss": 1.2086,
      "step": 15400
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.876973569393158,
      "learning_rate": 0.00025320299999999997,
      "loss": 1.2334,
      "step": 15600
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.5841688513755798,
      "learning_rate": 0.000252603,
      "loss": 1.1459,
      "step": 15800
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.1613374948501587,
      "learning_rate": 0.000252003,
      "loss": 1.2171,
      "step": 16000
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.9825133085250854,
      "learning_rate": 0.000251403,
      "loss": 1.2068,
      "step": 16200
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.906218409538269,
      "learning_rate": 0.00025080299999999996,
      "loss": 1.1566,
      "step": 16400
    },
    {
      "epoch": 0.332,
      "grad_norm": 1.6522161960601807,
      "learning_rate": 0.000250203,
      "loss": 1.1732,
      "step": 16600
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.8922094106674194,
      "learning_rate": 0.000249603,
      "loss": 1.1447,
      "step": 16800
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5361147522926331,
      "learning_rate": 0.000249003,
      "loss": 1.1992,
      "step": 17000
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.921966016292572,
      "learning_rate": 0.00024840299999999996,
      "loss": 1.1898,
      "step": 17200
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.8789780735969543,
      "learning_rate": 0.000247803,
      "loss": 1.1592,
      "step": 17400
    },
    {
      "epoch": 0.352,
      "grad_norm": 1.3642746210098267,
      "learning_rate": 0.000247203,
      "loss": 1.1673,
      "step": 17600
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.4741620719432831,
      "learning_rate": 0.00024660299999999997,
      "loss": 1.0993,
      "step": 17800
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.5090957880020142,
      "learning_rate": 0.000246003,
      "loss": 1.1444,
      "step": 18000
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.7947115302085876,
      "learning_rate": 0.000245403,
      "loss": 1.2006,
      "step": 18200
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.5335280895233154,
      "learning_rate": 0.000244803,
      "loss": 1.1165,
      "step": 18400
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.9348941445350647,
      "learning_rate": 0.00024420299999999997,
      "loss": 1.1845,
      "step": 18600
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.5035831928253174,
      "learning_rate": 0.00024360299999999998,
      "loss": 1.1514,
      "step": 18800
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6465203762054443,
      "learning_rate": 0.000243003,
      "loss": 1.1862,
      "step": 19000
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.7859534621238708,
      "learning_rate": 0.00024240299999999998,
      "loss": 1.0812,
      "step": 19200
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.589261531829834,
      "learning_rate": 0.000241803,
      "loss": 1.1106,
      "step": 19400
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.6167768239974976,
      "learning_rate": 0.00024120299999999997,
      "loss": 1.1517,
      "step": 19600
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.9388450384140015,
      "learning_rate": 0.000240603,
      "loss": 1.1348,
      "step": 19800
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7226972579956055,
      "learning_rate": 0.00024000299999999997,
      "loss": 1.098,
      "step": 20000
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.832726001739502,
      "learning_rate": 0.00023940299999999998,
      "loss": 1.073,
      "step": 20200
    },
    {
      "epoch": 0.408,
      "grad_norm": 1.0407387018203735,
      "learning_rate": 0.00023880299999999997,
      "loss": 1.1102,
      "step": 20400
    },
    {
      "epoch": 0.412,
      "grad_norm": 1.2114694118499756,
      "learning_rate": 0.00023820299999999998,
      "loss": 1.1982,
      "step": 20600
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.9036005735397339,
      "learning_rate": 0.00023760299999999997,
      "loss": 1.1082,
      "step": 20800
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6692425608634949,
      "learning_rate": 0.00023700299999999998,
      "loss": 1.1054,
      "step": 21000
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.5611643195152283,
      "learning_rate": 0.00023640299999999997,
      "loss": 1.1452,
      "step": 21200
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.5212030410766602,
      "learning_rate": 0.00023580299999999998,
      "loss": 1.0873,
      "step": 21400
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.5760377049446106,
      "learning_rate": 0.00023520299999999996,
      "loss": 1.1295,
      "step": 21600
    },
    {
      "epoch": 0.436,
      "grad_norm": 1.0746605396270752,
      "learning_rate": 0.00023460299999999998,
      "loss": 1.0413,
      "step": 21800
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4830220639705658,
      "learning_rate": 0.00023400299999999996,
      "loss": 1.1134,
      "step": 22000
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.8292837142944336,
      "learning_rate": 0.00023340299999999997,
      "loss": 1.1414,
      "step": 22200
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.7768941521644592,
      "learning_rate": 0.00023280299999999996,
      "loss": 1.132,
      "step": 22400
    },
    {
      "epoch": 0.452,
      "grad_norm": 2.238168239593506,
      "learning_rate": 0.00023220299999999997,
      "loss": 1.1443,
      "step": 22600
    },
    {
      "epoch": 0.456,
      "grad_norm": 1.287428617477417,
      "learning_rate": 0.00023160299999999998,
      "loss": 1.112,
      "step": 22800
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7678553462028503,
      "learning_rate": 0.00023100299999999997,
      "loss": 1.1199,
      "step": 23000
    },
    {
      "epoch": 0.464,
      "grad_norm": 1.0083675384521484,
      "learning_rate": 0.00023040299999999998,
      "loss": 1.1261,
      "step": 23200
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.7197780013084412,
      "learning_rate": 0.00022980299999999997,
      "loss": 1.1301,
      "step": 23400
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.7374047040939331,
      "learning_rate": 0.00022920299999999998,
      "loss": 1.0738,
      "step": 23600
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.9931918978691101,
      "learning_rate": 0.00022860299999999997,
      "loss": 1.0471,
      "step": 23800
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7919967174530029,
      "learning_rate": 0.00022800299999999998,
      "loss": 1.0922,
      "step": 24000
    },
    {
      "epoch": 0.484,
      "grad_norm": 1.5365839004516602,
      "learning_rate": 0.00022740299999999996,
      "loss": 1.111,
      "step": 24200
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.8887788653373718,
      "learning_rate": 0.00022680299999999998,
      "loss": 1.0389,
      "step": 24400
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.6709370613098145,
      "learning_rate": 0.00022620299999999996,
      "loss": 1.0569,
      "step": 24600
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.9460957050323486,
      "learning_rate": 0.00022560299999999997,
      "loss": 1.0806,
      "step": 24800
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.870838463306427,
      "learning_rate": 0.00022500299999999996,
      "loss": 1.0709,
      "step": 25000
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.7362083196640015,
      "learning_rate": 0.00022440299999999997,
      "loss": 1.1189,
      "step": 25200
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.9302026033401489,
      "learning_rate": 0.00022380299999999996,
      "loss": 1.0703,
      "step": 25400
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.9802331328392029,
      "learning_rate": 0.00022320299999999997,
      "loss": 1.0939,
      "step": 25600
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.9765194058418274,
      "learning_rate": 0.00022260299999999996,
      "loss": 1.0919,
      "step": 25800
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.9388764500617981,
      "learning_rate": 0.00022200299999999997,
      "loss": 1.0546,
      "step": 26000
    },
    {
      "epoch": 0.524,
      "grad_norm": 1.282112717628479,
      "learning_rate": 0.000221403,
      "loss": 1.1049,
      "step": 26200
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.7162898778915405,
      "learning_rate": 0.000220803,
      "loss": 1.0252,
      "step": 26400
    },
    {
      "epoch": 0.532,
      "grad_norm": 1.0185514688491821,
      "learning_rate": 0.000220203,
      "loss": 1.0957,
      "step": 26600
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.8791497945785522,
      "learning_rate": 0.000219603,
      "loss": 1.0317,
      "step": 26800
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7762041687965393,
      "learning_rate": 0.000219003,
      "loss": 1.0465,
      "step": 27000
    },
    {
      "epoch": 0.544,
      "grad_norm": 1.1519874334335327,
      "learning_rate": 0.000218403,
      "loss": 1.0394,
      "step": 27200
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.8509097695350647,
      "learning_rate": 0.000217803,
      "loss": 1.0395,
      "step": 27400
    },
    {
      "epoch": 0.552,
      "grad_norm": 2.2353217601776123,
      "learning_rate": 0.000217203,
      "loss": 1.0592,
      "step": 27600
    },
    {
      "epoch": 0.556,
      "grad_norm": 1.2266647815704346,
      "learning_rate": 0.000216603,
      "loss": 1.0911,
      "step": 27800
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7290273904800415,
      "learning_rate": 0.00021600299999999998,
      "loss": 1.0497,
      "step": 28000
    },
    {
      "epoch": 0.564,
      "grad_norm": 1.1230442523956299,
      "learning_rate": 0.000215403,
      "loss": 1.0195,
      "step": 28200
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.8819729089736938,
      "learning_rate": 0.00021480299999999998,
      "loss": 0.9881,
      "step": 28400
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.49670353531837463,
      "learning_rate": 0.000214203,
      "loss": 1.0532,
      "step": 28600
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.8848785758018494,
      "learning_rate": 0.00021360299999999998,
      "loss": 1.0567,
      "step": 28800
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.340657114982605,
      "learning_rate": 0.000213003,
      "loss": 1.0216,
      "step": 29000
    },
    {
      "epoch": 0.584,
      "grad_norm": 13.604581832885742,
      "learning_rate": 0.00021240299999999998,
      "loss": 1.0721,
      "step": 29200
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.9841917753219604,
      "learning_rate": 0.000211803,
      "loss": 1.0808,
      "step": 29400
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.6180630922317505,
      "learning_rate": 0.00021120299999999998,
      "loss": 1.0128,
      "step": 29600
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.938469409942627,
      "learning_rate": 0.000210603,
      "loss": 1.0074,
      "step": 29800
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.963956892490387,
      "learning_rate": 0.00021000299999999997,
      "loss": 1.0517,
      "step": 30000
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.8931580781936646,
      "learning_rate": 0.000209403,
      "loss": 1.0924,
      "step": 30200
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.6754233837127686,
      "learning_rate": 0.000208803,
      "loss": 0.9916,
      "step": 30400
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.6716899871826172,
      "learning_rate": 0.00020820299999999999,
      "loss": 1.0504,
      "step": 30600
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.3819950520992279,
      "learning_rate": 0.000207603,
      "loss": 1.0678,
      "step": 30800
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7109704613685608,
      "learning_rate": 0.00020700299999999998,
      "loss": 1.0353,
      "step": 31000
    },
    {
      "epoch": 0.624,
      "grad_norm": 1.0149035453796387,
      "learning_rate": 0.000206403,
      "loss": 1.0525,
      "step": 31200
    },
    {
      "epoch": 0.628,
      "grad_norm": 1.1604288816452026,
      "learning_rate": 0.00020580299999999998,
      "loss": 1.0927,
      "step": 31400
    },
    {
      "epoch": 0.632,
      "grad_norm": 1.470913052558899,
      "learning_rate": 0.000205203,
      "loss": 1.0204,
      "step": 31600
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.5736191272735596,
      "learning_rate": 0.00020460299999999998,
      "loss": 1.0591,
      "step": 31800
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5364808440208435,
      "learning_rate": 0.000204003,
      "loss": 1.0173,
      "step": 32000
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.7505438923835754,
      "learning_rate": 0.00020340299999999998,
      "loss": 0.9757,
      "step": 32200
    },
    {
      "epoch": 0.648,
      "grad_norm": 1.4492069482803345,
      "learning_rate": 0.000202803,
      "loss": 1.0596,
      "step": 32400
    },
    {
      "epoch": 0.652,
      "grad_norm": 1.0523359775543213,
      "learning_rate": 0.00020220299999999997,
      "loss": 1.0101,
      "step": 32600
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.7836924195289612,
      "learning_rate": 0.000201603,
      "loss": 0.9913,
      "step": 32800
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.006540060043335,
      "learning_rate": 0.00020100299999999997,
      "loss": 1.0182,
      "step": 33000
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.7113762497901917,
      "learning_rate": 0.00020040299999999999,
      "loss": 1.001,
      "step": 33200
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.9398137331008911,
      "learning_rate": 0.00019980299999999997,
      "loss": 0.9916,
      "step": 33400
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.662927508354187,
      "learning_rate": 0.00019920299999999998,
      "loss": 1.0365,
      "step": 33600
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.4947356581687927,
      "learning_rate": 0.00019860299999999997,
      "loss": 1.0553,
      "step": 33800
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9172172546386719,
      "learning_rate": 0.00019800299999999998,
      "loss": 0.9918,
      "step": 34000
    },
    {
      "epoch": 0.684,
      "grad_norm": 1.0629100799560547,
      "learning_rate": 0.00019740299999999997,
      "loss": 1.0042,
      "step": 34200
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.6189293265342712,
      "learning_rate": 0.00019680299999999998,
      "loss": 0.9721,
      "step": 34400
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.6072359085083008,
      "learning_rate": 0.00019620299999999996,
      "loss": 1.0316,
      "step": 34600
    },
    {
      "epoch": 0.696,
      "grad_norm": 1.0142394304275513,
      "learning_rate": 0.00019560299999999998,
      "loss": 1.0275,
      "step": 34800
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6736000776290894,
      "learning_rate": 0.00019500299999999996,
      "loss": 1.0119,
      "step": 35000
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.8150581121444702,
      "learning_rate": 0.00019440299999999997,
      "loss": 0.9955,
      "step": 35200
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.7659550309181213,
      "learning_rate": 0.000193803,
      "loss": 0.9974,
      "step": 35400
    },
    {
      "epoch": 0.712,
      "grad_norm": 1.2102367877960205,
      "learning_rate": 0.00019320299999999997,
      "loss": 0.9932,
      "step": 35600
    },
    {
      "epoch": 0.716,
      "grad_norm": 1.5642015933990479,
      "learning_rate": 0.00019260299999999999,
      "loss": 0.968,
      "step": 35800
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5257929563522339,
      "learning_rate": 0.00019200299999999997,
      "loss": 1.0058,
      "step": 36000
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.24982303380966187,
      "learning_rate": 0.00019140299999999998,
      "loss": 1.0346,
      "step": 36200
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.8046077489852905,
      "learning_rate": 0.00019080299999999997,
      "loss": 0.9958,
      "step": 36400
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.4914412498474121,
      "learning_rate": 0.00019020299999999998,
      "loss": 0.9472,
      "step": 36600
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.836391806602478,
      "learning_rate": 0.00018960299999999997,
      "loss": 0.9799,
      "step": 36800
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.740658700466156,
      "learning_rate": 0.00018900299999999998,
      "loss": 1.0056,
      "step": 37000
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.7024087905883789,
      "learning_rate": 0.00018840299999999996,
      "loss": 0.9641,
      "step": 37200
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.9077993631362915,
      "learning_rate": 0.00018780299999999998,
      "loss": 0.9703,
      "step": 37400
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.6558671593666077,
      "learning_rate": 0.00018720299999999996,
      "loss": 0.9821,
      "step": 37600
    },
    {
      "epoch": 0.756,
      "grad_norm": 1.570372462272644,
      "learning_rate": 0.00018660299999999998,
      "loss": 1.0125,
      "step": 37800
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.16595196723938,
      "learning_rate": 0.00018600299999999996,
      "loss": 1.0588,
      "step": 38000
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.8090103268623352,
      "learning_rate": 0.00018540299999999997,
      "loss": 0.9902,
      "step": 38200
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.673749566078186,
      "learning_rate": 0.00018480299999999996,
      "loss": 1.0002,
      "step": 38400
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.8080440163612366,
      "learning_rate": 0.00018420299999999997,
      "loss": 0.9918,
      "step": 38600
    },
    {
      "epoch": 0.776,
      "grad_norm": 1.5220410823822021,
      "learning_rate": 0.000183603,
      "loss": 0.9955,
      "step": 38800
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.051055669784546,
      "learning_rate": 0.000183003,
      "loss": 0.975,
      "step": 39000
    },
    {
      "epoch": 0.784,
      "grad_norm": 1.0487680435180664,
      "learning_rate": 0.000182403,
      "loss": 0.9883,
      "step": 39200
    },
    {
      "epoch": 0.788,
      "grad_norm": 1.3001760244369507,
      "learning_rate": 0.000181803,
      "loss": 0.9762,
      "step": 39400
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.577539324760437,
      "learning_rate": 0.000181203,
      "loss": 0.9546,
      "step": 39600
    },
    {
      "epoch": 0.796,
      "grad_norm": 1.5907810926437378,
      "learning_rate": 0.000180603,
      "loss": 0.9787,
      "step": 39800
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5472008585929871,
      "learning_rate": 0.000180003,
      "loss": 0.9775,
      "step": 40000
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.3289978802204132,
      "learning_rate": 0.000179403,
      "loss": 0.9826,
      "step": 40200
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.5331841707229614,
      "learning_rate": 0.000178803,
      "loss": 0.9801,
      "step": 40400
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.5353022813796997,
      "learning_rate": 0.000178203,
      "loss": 0.9443,
      "step": 40600
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.6574490070343018,
      "learning_rate": 0.000177603,
      "loss": 1.0416,
      "step": 40800
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3691502809524536,
      "learning_rate": 0.00017700299999999999,
      "loss": 0.9981,
      "step": 41000
    },
    {
      "epoch": 0.824,
      "grad_norm": 1.1122264862060547,
      "learning_rate": 0.000176403,
      "loss": 0.9491,
      "step": 41200
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.7167084217071533,
      "learning_rate": 0.00017580299999999998,
      "loss": 0.9934,
      "step": 41400
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.9672463536262512,
      "learning_rate": 0.000175203,
      "loss": 0.9726,
      "step": 41600
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.5368366241455078,
      "learning_rate": 0.00017460299999999998,
      "loss": 0.9912,
      "step": 41800
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.779911994934082,
      "learning_rate": 0.000174003,
      "loss": 0.9798,
      "step": 42000
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.6912847757339478,
      "learning_rate": 0.00017340299999999998,
      "loss": 1.0109,
      "step": 42200
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.8393747210502625,
      "learning_rate": 0.000172803,
      "loss": 0.9623,
      "step": 42400
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.6668691039085388,
      "learning_rate": 0.000172203,
      "loss": 1.0009,
      "step": 42600
    },
    {
      "epoch": 0.856,
      "grad_norm": 1.0019001960754395,
      "learning_rate": 0.000171603,
      "loss": 0.9991,
      "step": 42800
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.08681321144104,
      "learning_rate": 0.000171003,
      "loss": 0.9865,
      "step": 43000
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.9863645434379578,
      "learning_rate": 0.000170403,
      "loss": 0.9679,
      "step": 43200
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.5748602747917175,
      "learning_rate": 0.000169803,
      "loss": 0.948,
      "step": 43400
    },
    {
      "epoch": 0.872,
      "grad_norm": 1.2778534889221191,
      "learning_rate": 0.00016920299999999999,
      "loss": 0.9941,
      "step": 43600
    },
    {
      "epoch": 0.876,
      "grad_norm": 1.180475115776062,
      "learning_rate": 0.000168603,
      "loss": 0.9892,
      "step": 43800
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4378925561904907,
      "learning_rate": 0.00016800299999999998,
      "loss": 0.9539,
      "step": 44000
    },
    {
      "epoch": 0.884,
      "grad_norm": 1.0624910593032837,
      "learning_rate": 0.000167403,
      "loss": 1.021,
      "step": 44200
    },
    {
      "epoch": 0.888,
      "grad_norm": 1.363296627998352,
      "learning_rate": 0.00016680299999999998,
      "loss": 0.9927,
      "step": 44400
    },
    {
      "epoch": 0.892,
      "grad_norm": 1.0690699815750122,
      "learning_rate": 0.000166203,
      "loss": 0.9703,
      "step": 44600
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.5990111231803894,
      "learning_rate": 0.00016560299999999998,
      "loss": 0.9464,
      "step": 44800
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5669775009155273,
      "learning_rate": 0.000165003,
      "loss": 0.9456,
      "step": 45000
    },
    {
      "epoch": 0.904,
      "grad_norm": 3.2963221073150635,
      "learning_rate": 0.00016440299999999998,
      "loss": 0.9686,
      "step": 45200
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.6729605197906494,
      "learning_rate": 0.000163803,
      "loss": 0.9986,
      "step": 45400
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.9161190390586853,
      "learning_rate": 0.00016320299999999998,
      "loss": 0.9822,
      "step": 45600
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.48053523898124695,
      "learning_rate": 0.000162603,
      "loss": 0.9776,
      "step": 45800
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8575291037559509,
      "learning_rate": 0.00016200299999999997,
      "loss": 0.9939,
      "step": 46000
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.7615976333618164,
      "learning_rate": 0.00016140299999999999,
      "loss": 0.9553,
      "step": 46200
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.8894909024238586,
      "learning_rate": 0.00016080299999999997,
      "loss": 0.9865,
      "step": 46400
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.6745745539665222,
      "learning_rate": 0.00016020299999999998,
      "loss": 0.9601,
      "step": 46600
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.6472136378288269,
      "learning_rate": 0.00015960299999999997,
      "loss": 0.9464,
      "step": 46800
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.0426750183105469,
      "learning_rate": 0.00015900299999999998,
      "loss": 0.9458,
      "step": 47000
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.8287582993507385,
      "learning_rate": 0.00015840299999999997,
      "loss": 0.9297,
      "step": 47200
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.8560076951980591,
      "learning_rate": 0.00015780299999999998,
      "loss": 0.9104,
      "step": 47400
    },
    {
      "epoch": 0.952,
      "grad_norm": 1.1376183032989502,
      "learning_rate": 0.000157203,
      "loss": 0.9782,
      "step": 47600
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.6334831118583679,
      "learning_rate": 0.00015660299999999998,
      "loss": 0.94,
      "step": 47800
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.2437925338745117,
      "learning_rate": 0.000156003,
      "loss": 0.9961,
      "step": 48000
    },
    {
      "epoch": 0.964,
      "grad_norm": 1.0417191982269287,
      "learning_rate": 0.00015540299999999998,
      "loss": 0.9585,
      "step": 48200
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.5462374091148376,
      "learning_rate": 0.000154803,
      "loss": 0.969,
      "step": 48400
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.6307547092437744,
      "learning_rate": 0.00015420299999999997,
      "loss": 0.9447,
      "step": 48600
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.6743825674057007,
      "learning_rate": 0.00015360299999999999,
      "loss": 0.9422,
      "step": 48800
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.3121020793914795,
      "learning_rate": 0.00015300299999999997,
      "loss": 0.9267,
      "step": 49000
    },
    {
      "epoch": 0.984,
      "grad_norm": 1.536489725112915,
      "learning_rate": 0.00015240299999999998,
      "loss": 0.9703,
      "step": 49200
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.34768998622894287,
      "learning_rate": 0.00015180299999999997,
      "loss": 0.9723,
      "step": 49400
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.9410049915313721,
      "learning_rate": 0.00015120299999999998,
      "loss": 0.9369,
      "step": 49600
    },
    {
      "epoch": 0.996,
      "grad_norm": 1.1932367086410522,
      "learning_rate": 0.00015060299999999997,
      "loss": 0.9625,
      "step": 49800
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8710507154464722,
      "learning_rate": 0.00015000299999999998,
      "loss": 0.933,
      "step": 50000
    },
    {
      "epoch": 1.004,
      "grad_norm": 0.7907793521881104,
      "learning_rate": 0.000149403,
      "loss": 0.9515,
      "step": 50200
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.6152108311653137,
      "learning_rate": 0.00014880299999999998,
      "loss": 0.9751,
      "step": 50400
    },
    {
      "epoch": 1.012,
      "grad_norm": 0.7943951487541199,
      "learning_rate": 0.000148203,
      "loss": 0.9497,
      "step": 50600
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.8213640451431274,
      "learning_rate": 0.00014760299999999998,
      "loss": 0.9263,
      "step": 50800
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.5104868412017822,
      "learning_rate": 0.000147003,
      "loss": 0.9575,
      "step": 51000
    },
    {
      "epoch": 1.024,
      "grad_norm": 1.436120867729187,
      "learning_rate": 0.00014640299999999997,
      "loss": 0.9146,
      "step": 51200
    },
    {
      "epoch": 1.028,
      "grad_norm": 0.7340901494026184,
      "learning_rate": 0.00014580299999999999,
      "loss": 0.9165,
      "step": 51400
    },
    {
      "epoch": 1.032,
      "grad_norm": 1.5973939895629883,
      "learning_rate": 0.000145203,
      "loss": 0.9702,
      "step": 51600
    },
    {
      "epoch": 1.036,
      "grad_norm": 0.5281401872634888,
      "learning_rate": 0.00014460299999999998,
      "loss": 0.9157,
      "step": 51800
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.85554438829422,
      "learning_rate": 0.000144003,
      "loss": 0.9301,
      "step": 52000
    },
    {
      "epoch": 1.044,
      "grad_norm": 0.21773095428943634,
      "learning_rate": 0.00014340299999999998,
      "loss": 0.901,
      "step": 52200
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.7229174971580505,
      "learning_rate": 0.000142803,
      "loss": 0.9327,
      "step": 52400
    },
    {
      "epoch": 1.052,
      "grad_norm": 1.3107655048370361,
      "learning_rate": 0.00014220299999999998,
      "loss": 0.9524,
      "step": 52600
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.4953959584236145,
      "learning_rate": 0.000141603,
      "loss": 0.9923,
      "step": 52800
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.47346365451812744,
      "learning_rate": 0.00014100299999999998,
      "loss": 0.9396,
      "step": 53000
    },
    {
      "epoch": 1.064,
      "grad_norm": 1.0856235027313232,
      "learning_rate": 0.000140403,
      "loss": 0.9088,
      "step": 53200
    },
    {
      "epoch": 1.068,
      "grad_norm": 0.9282291531562805,
      "learning_rate": 0.00013980299999999998,
      "loss": 0.8946,
      "step": 53400
    },
    {
      "epoch": 1.072,
      "grad_norm": 1.5296639204025269,
      "learning_rate": 0.000139203,
      "loss": 0.9468,
      "step": 53600
    },
    {
      "epoch": 1.076,
      "grad_norm": 0.41474276781082153,
      "learning_rate": 0.00013860299999999997,
      "loss": 0.8881,
      "step": 53800
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.807451069355011,
      "learning_rate": 0.00013800299999999999,
      "loss": 0.9601,
      "step": 54000
    },
    {
      "epoch": 1.084,
      "grad_norm": 0.6471441388130188,
      "learning_rate": 0.00013740299999999997,
      "loss": 0.8942,
      "step": 54200
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.8642488121986389,
      "learning_rate": 0.00013680299999999998,
      "loss": 0.9218,
      "step": 54400
    },
    {
      "epoch": 1.092,
      "grad_norm": 0.2678181827068329,
      "learning_rate": 0.000136203,
      "loss": 0.9246,
      "step": 54600
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.5594624280929565,
      "learning_rate": 0.00013560299999999998,
      "loss": 0.9258,
      "step": 54800
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.9221727848052979,
      "learning_rate": 0.000135003,
      "loss": 0.9558,
      "step": 55000
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.7266154885292053,
      "learning_rate": 0.000134403,
      "loss": 0.8964,
      "step": 55200
    },
    {
      "epoch": 1.108,
      "grad_norm": 0.6107046604156494,
      "learning_rate": 0.000133803,
      "loss": 0.9226,
      "step": 55400
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.7604200839996338,
      "learning_rate": 0.000133203,
      "loss": 0.9097,
      "step": 55600
    },
    {
      "epoch": 1.116,
      "grad_norm": 0.8110626935958862,
      "learning_rate": 0.000132603,
      "loss": 0.9293,
      "step": 55800
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.9112208485603333,
      "learning_rate": 0.000132003,
      "loss": 0.9326,
      "step": 56000
    },
    {
      "epoch": 1.124,
      "grad_norm": 0.5522721409797668,
      "learning_rate": 0.000131403,
      "loss": 0.9091,
      "step": 56200
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.6214655041694641,
      "learning_rate": 0.000130803,
      "loss": 0.9089,
      "step": 56400
    },
    {
      "epoch": 1.1320000000000001,
      "grad_norm": 0.7262511849403381,
      "learning_rate": 0.000130203,
      "loss": 0.9147,
      "step": 56600
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.9000979661941528,
      "learning_rate": 0.000129603,
      "loss": 0.8948,
      "step": 56800
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 0.904468834400177,
      "learning_rate": 0.00012900299999999998,
      "loss": 0.9515,
      "step": 57000
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.6248944401741028,
      "learning_rate": 0.000128403,
      "loss": 0.9142,
      "step": 57200
    },
    {
      "epoch": 1.148,
      "grad_norm": 1.1241639852523804,
      "learning_rate": 0.00012780299999999998,
      "loss": 0.9196,
      "step": 57400
    },
    {
      "epoch": 1.152,
      "grad_norm": 1.6713260412216187,
      "learning_rate": 0.000127203,
      "loss": 0.8993,
      "step": 57600
    },
    {
      "epoch": 1.156,
      "grad_norm": 0.7987263798713684,
      "learning_rate": 0.00012660299999999998,
      "loss": 0.9319,
      "step": 57800
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.1742271184921265,
      "learning_rate": 0.000126003,
      "loss": 0.88,
      "step": 58000
    },
    {
      "epoch": 1.164,
      "grad_norm": 0.9136051535606384,
      "learning_rate": 0.00012540299999999998,
      "loss": 0.8959,
      "step": 58200
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.6379744410514832,
      "learning_rate": 0.000124803,
      "loss": 0.9396,
      "step": 58400
    },
    {
      "epoch": 1.172,
      "grad_norm": 0.7836189866065979,
      "learning_rate": 0.00012420299999999998,
      "loss": 0.9208,
      "step": 58600
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.8461201786994934,
      "learning_rate": 0.000123603,
      "loss": 0.9665,
      "step": 58800
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6077851057052612,
      "learning_rate": 0.00012300299999999997,
      "loss": 0.8983,
      "step": 59000
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.5138780474662781,
      "learning_rate": 0.000122403,
      "loss": 0.9004,
      "step": 59200
    },
    {
      "epoch": 1.188,
      "grad_norm": 0.5311010479927063,
      "learning_rate": 0.00012180299999999999,
      "loss": 0.927,
      "step": 59400
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.7904216647148132,
      "learning_rate": 0.00012120299999999998,
      "loss": 0.9483,
      "step": 59600
    },
    {
      "epoch": 1.196,
      "grad_norm": 1.309455394744873,
      "learning_rate": 0.00012060299999999998,
      "loss": 0.9318,
      "step": 59800
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.31221604347229,
      "learning_rate": 0.00012000299999999998,
      "loss": 0.9192,
      "step": 60000
    },
    {
      "epoch": 1.204,
      "grad_norm": 0.5596024990081787,
      "learning_rate": 0.00011940299999999998,
      "loss": 0.9394,
      "step": 60200
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.7620700597763062,
      "learning_rate": 0.00011880299999999998,
      "loss": 0.9504,
      "step": 60400
    },
    {
      "epoch": 1.212,
      "grad_norm": 1.2938125133514404,
      "learning_rate": 0.00011820299999999999,
      "loss": 0.9549,
      "step": 60600
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.3009229302406311,
      "learning_rate": 0.00011760299999999999,
      "loss": 0.9003,
      "step": 60800
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.7463399171829224,
      "learning_rate": 0.00011700299999999999,
      "loss": 0.8903,
      "step": 61000
    },
    {
      "epoch": 1.224,
      "grad_norm": 1.3211272954940796,
      "learning_rate": 0.00011640299999999999,
      "loss": 0.9277,
      "step": 61200
    },
    {
      "epoch": 1.228,
      "grad_norm": 1.9605532884597778,
      "learning_rate": 0.000115803,
      "loss": 0.9198,
      "step": 61400
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.6491342782974243,
      "learning_rate": 0.000115203,
      "loss": 0.9259,
      "step": 61600
    },
    {
      "epoch": 1.236,
      "grad_norm": 0.5725081562995911,
      "learning_rate": 0.000114603,
      "loss": 0.8992,
      "step": 61800
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.9162931442260742,
      "learning_rate": 0.000114003,
      "loss": 0.9142,
      "step": 62000
    },
    {
      "epoch": 1.244,
      "grad_norm": 0.5548607707023621,
      "learning_rate": 0.000113403,
      "loss": 0.9068,
      "step": 62200
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.9710361957550049,
      "learning_rate": 0.000112803,
      "loss": 0.9462,
      "step": 62400
    },
    {
      "epoch": 1.252,
      "grad_norm": 1.1876705884933472,
      "learning_rate": 0.000112203,
      "loss": 0.8777,
      "step": 62600
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.4929996728897095,
      "learning_rate": 0.000111603,
      "loss": 0.8968,
      "step": 62800
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.0502116680145264,
      "learning_rate": 0.000111003,
      "loss": 0.878,
      "step": 63000
    },
    {
      "epoch": 1.264,
      "grad_norm": 1.416930913925171,
      "learning_rate": 0.00011040299999999999,
      "loss": 0.902,
      "step": 63200
    },
    {
      "epoch": 1.268,
      "grad_norm": 0.8568691611289978,
      "learning_rate": 0.00010980299999999999,
      "loss": 0.8583,
      "step": 63400
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.4070914685726166,
      "learning_rate": 0.00010920299999999999,
      "loss": 0.9253,
      "step": 63600
    },
    {
      "epoch": 1.276,
      "grad_norm": 0.28898558020591736,
      "learning_rate": 0.00010860299999999999,
      "loss": 0.8923,
      "step": 63800
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.1990442276000977,
      "learning_rate": 0.00010800299999999999,
      "loss": 0.8456,
      "step": 64000
    },
    {
      "epoch": 1.284,
      "grad_norm": 0.5257548093795776,
      "learning_rate": 0.00010740299999999999,
      "loss": 0.8801,
      "step": 64200
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.7115829586982727,
      "learning_rate": 0.00010680299999999999,
      "loss": 0.8984,
      "step": 64400
    },
    {
      "epoch": 1.292,
      "grad_norm": 0.9477531313896179,
      "learning_rate": 0.00010620299999999999,
      "loss": 0.9015,
      "step": 64600
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.8855891227722168,
      "learning_rate": 0.00010560299999999998,
      "loss": 0.8698,
      "step": 64800
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.2653230428695679,
      "learning_rate": 0.00010500299999999998,
      "loss": 0.8741,
      "step": 65000
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.9070186614990234,
      "learning_rate": 0.00010440299999999998,
      "loss": 0.9124,
      "step": 65200
    },
    {
      "epoch": 1.308,
      "grad_norm": 0.6937887668609619,
      "learning_rate": 0.00010380299999999998,
      "loss": 0.8751,
      "step": 65400
    },
    {
      "epoch": 1.312,
      "grad_norm": 1.0945773124694824,
      "learning_rate": 0.00010320299999999998,
      "loss": 0.9123,
      "step": 65600
    },
    {
      "epoch": 1.316,
      "grad_norm": 0.8044648170471191,
      "learning_rate": 0.00010260299999999998,
      "loss": 0.9362,
      "step": 65800
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.5347235202789307,
      "learning_rate": 0.00010200299999999998,
      "loss": 0.9075,
      "step": 66000
    },
    {
      "epoch": 1.324,
      "grad_norm": 1.0535420179367065,
      "learning_rate": 0.00010140299999999998,
      "loss": 0.9237,
      "step": 66200
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.8335495591163635,
      "learning_rate": 0.00010080299999999999,
      "loss": 0.9061,
      "step": 66400
    },
    {
      "epoch": 1.332,
      "grad_norm": 0.6612635850906372,
      "learning_rate": 0.00010020299999999999,
      "loss": 0.8956,
      "step": 66600
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.7188587188720703,
      "learning_rate": 9.9603e-05,
      "loss": 0.9023,
      "step": 66800
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6892597675323486,
      "learning_rate": 9.9003e-05,
      "loss": 0.9358,
      "step": 67000
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.6579219102859497,
      "learning_rate": 9.8403e-05,
      "loss": 0.8665,
      "step": 67200
    },
    {
      "epoch": 1.3479999999999999,
      "grad_norm": 0.8273529410362244,
      "learning_rate": 9.7803e-05,
      "loss": 0.9153,
      "step": 67400
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 1.1561954021453857,
      "learning_rate": 9.7203e-05,
      "loss": 0.9311,
      "step": 67600
    },
    {
      "epoch": 1.3559999999999999,
      "grad_norm": 0.6513040065765381,
      "learning_rate": 9.6603e-05,
      "loss": 0.9205,
      "step": 67800
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.8619893789291382,
      "learning_rate": 9.6003e-05,
      "loss": 0.9085,
      "step": 68000
    },
    {
      "epoch": 1.3639999999999999,
      "grad_norm": 0.5291149616241455,
      "learning_rate": 9.5403e-05,
      "loss": 0.8982,
      "step": 68200
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.7065431475639343,
      "learning_rate": 9.4803e-05,
      "loss": 0.9112,
      "step": 68400
    },
    {
      "epoch": 1.3719999999999999,
      "grad_norm": 1.095034122467041,
      "learning_rate": 9.420299999999999e-05,
      "loss": 0.9063,
      "step": 68600
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.588524341583252,
      "learning_rate": 9.360299999999999e-05,
      "loss": 0.8896,
      "step": 68800
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.5582250952720642,
      "learning_rate": 9.300299999999999e-05,
      "loss": 0.8712,
      "step": 69000
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.5464124083518982,
      "learning_rate": 9.240299999999999e-05,
      "loss": 0.8604,
      "step": 69200
    },
    {
      "epoch": 1.388,
      "grad_norm": 0.6255683898925781,
      "learning_rate": 9.180299999999999e-05,
      "loss": 0.8868,
      "step": 69400
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.8754594326019287,
      "learning_rate": 9.120299999999999e-05,
      "loss": 0.9198,
      "step": 69600
    },
    {
      "epoch": 1.396,
      "grad_norm": 0.5482944846153259,
      "learning_rate": 9.060299999999999e-05,
      "loss": 0.8904,
      "step": 69800
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.1412419080734253,
      "learning_rate": 9.000299999999999e-05,
      "loss": 0.9268,
      "step": 70000
    },
    {
      "epoch": 1.404,
      "grad_norm": 0.8849658370018005,
      "learning_rate": 8.9403e-05,
      "loss": 0.8919,
      "step": 70200
    },
    {
      "epoch": 1.408,
      "grad_norm": 1.2171194553375244,
      "learning_rate": 8.8803e-05,
      "loss": 0.9297,
      "step": 70400
    },
    {
      "epoch": 1.412,
      "grad_norm": 0.6867631673812866,
      "learning_rate": 8.8203e-05,
      "loss": 0.9077,
      "step": 70600
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.7091575264930725,
      "learning_rate": 8.7603e-05,
      "loss": 0.9281,
      "step": 70800
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.384539008140564,
      "learning_rate": 8.7003e-05,
      "loss": 0.8753,
      "step": 71000
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.6703789830207825,
      "learning_rate": 8.640299999999999e-05,
      "loss": 0.902,
      "step": 71200
    },
    {
      "epoch": 1.428,
      "grad_norm": 0.7404423356056213,
      "learning_rate": 8.580299999999999e-05,
      "loss": 0.8827,
      "step": 71400
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.6714608073234558,
      "learning_rate": 8.520299999999999e-05,
      "loss": 0.9202,
      "step": 71600
    },
    {
      "epoch": 1.436,
      "grad_norm": 0.584955096244812,
      "learning_rate": 8.460299999999999e-05,
      "loss": 0.8768,
      "step": 71800
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.7296590209007263,
      "learning_rate": 8.400299999999999e-05,
      "loss": 0.9096,
      "step": 72000
    },
    {
      "epoch": 1.444,
      "grad_norm": 0.7415053844451904,
      "learning_rate": 8.340299999999999e-05,
      "loss": 0.9026,
      "step": 72200
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.47887516021728516,
      "learning_rate": 8.280299999999999e-05,
      "loss": 0.847,
      "step": 72400
    },
    {
      "epoch": 1.452,
      "grad_norm": 0.9844368696212769,
      "learning_rate": 8.220299999999999e-05,
      "loss": 0.884,
      "step": 72600
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.662135660648346,
      "learning_rate": 8.160299999999998e-05,
      "loss": 0.933,
      "step": 72800
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.9067819118499756,
      "learning_rate": 8.100299999999998e-05,
      "loss": 0.8966,
      "step": 73000
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.7947647571563721,
      "learning_rate": 8.0403e-05,
      "loss": 0.9204,
      "step": 73200
    },
    {
      "epoch": 1.468,
      "grad_norm": 0.6790484189987183,
      "learning_rate": 7.9803e-05,
      "loss": 0.9079,
      "step": 73400
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.48600080609321594,
      "learning_rate": 7.9203e-05,
      "loss": 0.8805,
      "step": 73600
    },
    {
      "epoch": 1.476,
      "grad_norm": 1.7715222835540771,
      "learning_rate": 7.860299999999999e-05,
      "loss": 0.9087,
      "step": 73800
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.30095359683036804,
      "learning_rate": 7.8003e-05,
      "loss": 0.8532,
      "step": 74000
    },
    {
      "epoch": 1.484,
      "grad_norm": 1.210335612297058,
      "learning_rate": 7.7403e-05,
      "loss": 0.9193,
      "step": 74200
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.7150869369506836,
      "learning_rate": 7.6803e-05,
      "loss": 0.9315,
      "step": 74400
    },
    {
      "epoch": 1.492,
      "grad_norm": 0.6574634313583374,
      "learning_rate": 7.6203e-05,
      "loss": 0.8511,
      "step": 74600
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.6710678935050964,
      "learning_rate": 7.5603e-05,
      "loss": 0.8686,
      "step": 74800
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6900939345359802,
      "learning_rate": 7.5003e-05,
      "loss": 0.8848,
      "step": 75000
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.847480833530426,
      "learning_rate": 7.4403e-05,
      "loss": 0.8549,
      "step": 75200
    },
    {
      "epoch": 1.508,
      "grad_norm": 0.682520866394043,
      "learning_rate": 7.3803e-05,
      "loss": 0.8614,
      "step": 75400
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.6577958464622498,
      "learning_rate": 7.3203e-05,
      "loss": 0.9002,
      "step": 75600
    },
    {
      "epoch": 1.516,
      "grad_norm": 0.6087453365325928,
      "learning_rate": 7.2603e-05,
      "loss": 0.8843,
      "step": 75800
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.4171137809753418,
      "learning_rate": 7.2003e-05,
      "loss": 0.8784,
      "step": 76000
    },
    {
      "epoch": 1.524,
      "grad_norm": 0.6576541066169739,
      "learning_rate": 7.1403e-05,
      "loss": 0.9266,
      "step": 76200
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.20768269896507263,
      "learning_rate": 7.080299999999999e-05,
      "loss": 0.8739,
      "step": 76400
    },
    {
      "epoch": 1.532,
      "grad_norm": 0.6199871301651001,
      "learning_rate": 7.020299999999999e-05,
      "loss": 0.8449,
      "step": 76600
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.552604615688324,
      "learning_rate": 6.960299999999999e-05,
      "loss": 0.8817,
      "step": 76800
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.8390688300132751,
      "learning_rate": 6.900299999999999e-05,
      "loss": 0.9094,
      "step": 77000
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.7557447552680969,
      "learning_rate": 6.840299999999999e-05,
      "loss": 0.9051,
      "step": 77200
    },
    {
      "epoch": 1.548,
      "grad_norm": 0.5118599534034729,
      "learning_rate": 6.780299999999999e-05,
      "loss": 0.9339,
      "step": 77400
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.8651351928710938,
      "learning_rate": 6.720299999999999e-05,
      "loss": 0.9271,
      "step": 77600
    },
    {
      "epoch": 1.556,
      "grad_norm": 0.31793418526649475,
      "learning_rate": 6.6603e-05,
      "loss": 0.8751,
      "step": 77800
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.8064829111099243,
      "learning_rate": 6.6003e-05,
      "loss": 0.9055,
      "step": 78000
    },
    {
      "epoch": 1.564,
      "grad_norm": 0.869324803352356,
      "learning_rate": 6.5403e-05,
      "loss": 0.8912,
      "step": 78200
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.7603241801261902,
      "learning_rate": 6.4803e-05,
      "loss": 0.8862,
      "step": 78400
    },
    {
      "epoch": 1.572,
      "grad_norm": 0.43242147564888,
      "learning_rate": 6.4203e-05,
      "loss": 0.8919,
      "step": 78600
    },
    {
      "epoch": 1.576,
      "grad_norm": 1.017897367477417,
      "learning_rate": 6.3603e-05,
      "loss": 0.8964,
      "step": 78800
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6769782304763794,
      "learning_rate": 6.300299999999999e-05,
      "loss": 0.8851,
      "step": 79000
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.6568334102630615,
      "learning_rate": 6.240299999999999e-05,
      "loss": 0.8756,
      "step": 79200
    },
    {
      "epoch": 1.588,
      "grad_norm": 0.5511359572410583,
      "learning_rate": 6.180299999999999e-05,
      "loss": 0.9364,
      "step": 79400
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.8803353905677795,
      "learning_rate": 6.120299999999999e-05,
      "loss": 0.8737,
      "step": 79600
    },
    {
      "epoch": 1.596,
      "grad_norm": 0.5669352412223816,
      "learning_rate": 6.0602999999999996e-05,
      "loss": 0.902,
      "step": 79800
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.861292839050293,
      "learning_rate": 6.0002999999999995e-05,
      "loss": 0.8757,
      "step": 80000
    },
    {
      "epoch": 1.604,
      "grad_norm": 0.7968796491622925,
      "learning_rate": 5.9402999999999994e-05,
      "loss": 0.9034,
      "step": 80200
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.7109596133232117,
      "learning_rate": 5.880299999999999e-05,
      "loss": 0.8714,
      "step": 80400
    },
    {
      "epoch": 1.612,
      "grad_norm": 0.5549333095550537,
      "learning_rate": 5.820299999999999e-05,
      "loss": 0.8822,
      "step": 80600
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.9588609933853149,
      "learning_rate": 5.760299999999999e-05,
      "loss": 0.8897,
      "step": 80800
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.783277690410614,
      "learning_rate": 5.7002999999999996e-05,
      "loss": 0.877,
      "step": 81000
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.6864006519317627,
      "learning_rate": 5.6402999999999995e-05,
      "loss": 0.8685,
      "step": 81200
    },
    {
      "epoch": 1.6280000000000001,
      "grad_norm": 1.090616226196289,
      "learning_rate": 5.5803e-05,
      "loss": 0.896,
      "step": 81400
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.9071444272994995,
      "learning_rate": 5.5203e-05,
      "loss": 0.893,
      "step": 81600
    },
    {
      "epoch": 1.6360000000000001,
      "grad_norm": 0.7770195007324219,
      "learning_rate": 5.4603e-05,
      "loss": 0.8662,
      "step": 81800
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.5208815932273865,
      "learning_rate": 5.4003e-05,
      "loss": 0.8855,
      "step": 82000
    },
    {
      "epoch": 1.6440000000000001,
      "grad_norm": 0.6398658156394958,
      "learning_rate": 5.3403e-05,
      "loss": 0.8858,
      "step": 82200
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 1.7564977407455444,
      "learning_rate": 5.2802999999999996e-05,
      "loss": 0.906,
      "step": 82400
    },
    {
      "epoch": 1.6520000000000001,
      "grad_norm": 0.8796799182891846,
      "learning_rate": 5.2202999999999995e-05,
      "loss": 0.8667,
      "step": 82600
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.40589243173599243,
      "learning_rate": 5.1602999999999994e-05,
      "loss": 0.9333,
      "step": 82800
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 0.7749320268630981,
      "learning_rate": 5.100299999999999e-05,
      "loss": 0.8466,
      "step": 83000
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 1.1142667531967163,
      "learning_rate": 5.040299999999999e-05,
      "loss": 0.8919,
      "step": 83200
    },
    {
      "epoch": 1.6680000000000001,
      "grad_norm": 0.7933562994003296,
      "learning_rate": 4.980299999999999e-05,
      "loss": 0.9023,
      "step": 83400
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.6007291674613953,
      "learning_rate": 4.920299999999999e-05,
      "loss": 0.8785,
      "step": 83600
    },
    {
      "epoch": 1.6760000000000002,
      "grad_norm": 0.42440974712371826,
      "learning_rate": 4.8602999999999995e-05,
      "loss": 0.9349,
      "step": 83800
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.5134540796279907,
      "learning_rate": 4.8003e-05,
      "loss": 0.8697,
      "step": 84000
    },
    {
      "epoch": 1.6840000000000002,
      "grad_norm": 0.5223248600959778,
      "learning_rate": 4.7403e-05,
      "loss": 0.8757,
      "step": 84200
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.8424768447875977,
      "learning_rate": 4.6803e-05,
      "loss": 0.848,
      "step": 84400
    },
    {
      "epoch": 1.692,
      "grad_norm": 0.691382884979248,
      "learning_rate": 4.6203e-05,
      "loss": 0.8604,
      "step": 84600
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.6498924493789673,
      "learning_rate": 4.5603e-05,
      "loss": 0.8479,
      "step": 84800
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.9186570048332214,
      "learning_rate": 4.5002999999999996e-05,
      "loss": 0.8817,
      "step": 85000
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.6840952634811401,
      "learning_rate": 4.4402999999999995e-05,
      "loss": 0.8601,
      "step": 85200
    },
    {
      "epoch": 1.708,
      "grad_norm": 0.556609570980072,
      "learning_rate": 4.3802999999999994e-05,
      "loss": 0.8965,
      "step": 85400
    },
    {
      "epoch": 1.712,
      "grad_norm": 1.832463026046753,
      "learning_rate": 4.320299999999999e-05,
      "loss": 0.853,
      "step": 85600
    },
    {
      "epoch": 1.716,
      "grad_norm": 1.8699655532836914,
      "learning_rate": 4.2603e-05,
      "loss": 0.9001,
      "step": 85800
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.60898756980896,
      "learning_rate": 4.2003e-05,
      "loss": 0.8998,
      "step": 86000
    },
    {
      "epoch": 1.724,
      "grad_norm": 0.35642582178115845,
      "learning_rate": 4.1402999999999996e-05,
      "loss": 0.8477,
      "step": 86200
    },
    {
      "epoch": 1.728,
      "grad_norm": 1.1219841241836548,
      "learning_rate": 4.0802999999999995e-05,
      "loss": 0.8977,
      "step": 86400
    },
    {
      "epoch": 1.732,
      "grad_norm": 0.6081319451332092,
      "learning_rate": 4.0202999999999994e-05,
      "loss": 0.8626,
      "step": 86600
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.2534703314304352,
      "learning_rate": 3.960299999999999e-05,
      "loss": 0.8827,
      "step": 86800
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.7438156008720398,
      "learning_rate": 3.900299999999999e-05,
      "loss": 0.8942,
      "step": 87000
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.6403123140335083,
      "learning_rate": 3.8403e-05,
      "loss": 0.8981,
      "step": 87200
    },
    {
      "epoch": 1.748,
      "grad_norm": 1.1726515293121338,
      "learning_rate": 3.7803e-05,
      "loss": 0.8979,
      "step": 87400
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.955988347530365,
      "learning_rate": 3.7202999999999996e-05,
      "loss": 0.8998,
      "step": 87600
    },
    {
      "epoch": 1.756,
      "grad_norm": 0.6459194421768188,
      "learning_rate": 3.6602999999999995e-05,
      "loss": 0.8925,
      "step": 87800
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.6755852699279785,
      "learning_rate": 3.6003e-05,
      "loss": 0.8364,
      "step": 88000
    },
    {
      "epoch": 1.764,
      "grad_norm": 0.37415754795074463,
      "learning_rate": 3.5403e-05,
      "loss": 0.8422,
      "step": 88200
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.7628709673881531,
      "learning_rate": 3.4803e-05,
      "loss": 0.8647,
      "step": 88400
    },
    {
      "epoch": 1.772,
      "grad_norm": 2.7437870502471924,
      "learning_rate": 3.4203e-05,
      "loss": 0.8262,
      "step": 88600
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.7378831505775452,
      "learning_rate": 3.3602999999999997e-05,
      "loss": 0.86,
      "step": 88800
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.3208828866481781,
      "learning_rate": 3.3002999999999996e-05,
      "loss": 0.8647,
      "step": 89000
    },
    {
      "epoch": 1.784,
      "grad_norm": 1.3446178436279297,
      "learning_rate": 3.2402999999999995e-05,
      "loss": 0.875,
      "step": 89200
    },
    {
      "epoch": 1.788,
      "grad_norm": 0.9004704356193542,
      "learning_rate": 3.1802999999999993e-05,
      "loss": 0.9009,
      "step": 89400
    },
    {
      "epoch": 1.792,
      "grad_norm": 2.6994802951812744,
      "learning_rate": 3.1203e-05,
      "loss": 0.9088,
      "step": 89600
    },
    {
      "epoch": 1.796,
      "grad_norm": 0.8106651306152344,
      "learning_rate": 3.0603e-05,
      "loss": 0.9259,
      "step": 89800
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6139752864837646,
      "learning_rate": 3.0002999999999997e-05,
      "loss": 0.852,
      "step": 90000
    },
    {
      "epoch": 1.804,
      "grad_norm": 0.9431705474853516,
      "learning_rate": 2.9402999999999996e-05,
      "loss": 0.8766,
      "step": 90200
    },
    {
      "epoch": 1.808,
      "grad_norm": 1.2726632356643677,
      "learning_rate": 2.8803e-05,
      "loss": 0.8254,
      "step": 90400
    },
    {
      "epoch": 1.812,
      "grad_norm": 0.38621291518211365,
      "learning_rate": 2.8202999999999997e-05,
      "loss": 0.8889,
      "step": 90600
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.5755138397216797,
      "learning_rate": 2.7602999999999996e-05,
      "loss": 0.8809,
      "step": 90800
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 1.037194848060608,
      "learning_rate": 2.7003e-05,
      "loss": 0.8674,
      "step": 91000
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.9651980996131897,
      "learning_rate": 2.6402999999999998e-05,
      "loss": 0.8698,
      "step": 91200
    },
    {
      "epoch": 1.8279999999999998,
      "grad_norm": 0.7683670520782471,
      "learning_rate": 2.5803e-05,
      "loss": 0.8399,
      "step": 91400
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.77281254529953,
      "learning_rate": 2.5203e-05,
      "loss": 0.8919,
      "step": 91600
    },
    {
      "epoch": 1.8359999999999999,
      "grad_norm": 1.521257758140564,
      "learning_rate": 2.4602999999999998e-05,
      "loss": 0.8387,
      "step": 91800
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.7447263598442078,
      "learning_rate": 2.4002999999999997e-05,
      "loss": 0.8931,
      "step": 92000
    },
    {
      "epoch": 1.8439999999999999,
      "grad_norm": 0.7428454756736755,
      "learning_rate": 2.3402999999999996e-05,
      "loss": 0.8769,
      "step": 92200
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.707348644733429,
      "learning_rate": 2.2802999999999995e-05,
      "loss": 0.8746,
      "step": 92400
    },
    {
      "epoch": 1.8519999999999999,
      "grad_norm": 0.5701563954353333,
      "learning_rate": 2.2203e-05,
      "loss": 0.8937,
      "step": 92600
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.7288898229598999,
      "learning_rate": 2.1603e-05,
      "loss": 0.9238,
      "step": 92800
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 0.9206082224845886,
      "learning_rate": 2.1003e-05,
      "loss": 0.8957,
      "step": 93000
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.7663587927818298,
      "learning_rate": 2.0402999999999998e-05,
      "loss": 0.8387,
      "step": 93200
    },
    {
      "epoch": 1.8679999999999999,
      "grad_norm": 0.6312614679336548,
      "learning_rate": 1.9802999999999997e-05,
      "loss": 0.9203,
      "step": 93400
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.9284825325012207,
      "learning_rate": 1.9203e-05,
      "loss": 0.8427,
      "step": 93600
    },
    {
      "epoch": 1.876,
      "grad_norm": 0.7063210606575012,
      "learning_rate": 1.8602999999999998e-05,
      "loss": 0.8396,
      "step": 93800
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.816010594367981,
      "learning_rate": 1.8003e-05,
      "loss": 0.8771,
      "step": 94000
    },
    {
      "epoch": 1.884,
      "grad_norm": 0.8684834241867065,
      "learning_rate": 1.7403e-05,
      "loss": 0.8942,
      "step": 94200
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.6456332802772522,
      "learning_rate": 1.6802999999999998e-05,
      "loss": 0.8989,
      "step": 94400
    },
    {
      "epoch": 1.892,
      "grad_norm": 1.016007900238037,
      "learning_rate": 1.6203e-05,
      "loss": 0.8725,
      "step": 94600
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.4711146354675293,
      "learning_rate": 1.5603e-05,
      "loss": 0.8429,
      "step": 94800
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.7493122816085815,
      "learning_rate": 1.5002999999999998e-05,
      "loss": 0.9081,
      "step": 95000
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.7257886528968811,
      "learning_rate": 1.4402999999999997e-05,
      "loss": 0.8769,
      "step": 95200
    },
    {
      "epoch": 1.908,
      "grad_norm": 0.5162622332572937,
      "learning_rate": 1.3803e-05,
      "loss": 0.8702,
      "step": 95400
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.9234997034072876,
      "learning_rate": 1.3202999999999999e-05,
      "loss": 0.8504,
      "step": 95600
    },
    {
      "epoch": 1.916,
      "grad_norm": 0.634983479976654,
      "learning_rate": 1.2602999999999998e-05,
      "loss": 0.8665,
      "step": 95800
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.5892624855041504,
      "learning_rate": 1.2002999999999998e-05,
      "loss": 0.8939,
      "step": 96000
    },
    {
      "epoch": 1.924,
      "grad_norm": 0.6144778728485107,
      "learning_rate": 1.1402999999999999e-05,
      "loss": 0.8584,
      "step": 96200
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.8637000322341919,
      "learning_rate": 1.0803e-05,
      "loss": 0.8688,
      "step": 96400
    },
    {
      "epoch": 1.932,
      "grad_norm": 0.7883893847465515,
      "learning_rate": 1.0202999999999999e-05,
      "loss": 0.8764,
      "step": 96600
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.8425858020782471,
      "learning_rate": 9.602999999999998e-06,
      "loss": 0.8644,
      "step": 96800
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.9786319732666016,
      "learning_rate": 9.002999999999998e-06,
      "loss": 0.8297,
      "step": 97000
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.7675416469573975,
      "learning_rate": 8.402999999999999e-06,
      "loss": 0.8389,
      "step": 97200
    },
    {
      "epoch": 1.948,
      "grad_norm": 0.7833433747291565,
      "learning_rate": 7.803e-06,
      "loss": 0.8491,
      "step": 97400
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.5657205581665039,
      "learning_rate": 7.2029999999999995e-06,
      "loss": 0.817,
      "step": 97600
    },
    {
      "epoch": 1.956,
      "grad_norm": 1.5867365598678589,
      "learning_rate": 6.602999999999999e-06,
      "loss": 0.8607,
      "step": 97800
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.2415392398834229,
      "learning_rate": 6.002999999999999e-06,
      "loss": 0.8,
      "step": 98000
    },
    {
      "epoch": 1.964,
      "grad_norm": 0.4284496009349823,
      "learning_rate": 5.403e-06,
      "loss": 0.8378,
      "step": 98200
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.663853108882904,
      "learning_rate": 4.803e-06,
      "loss": 0.834,
      "step": 98400
    },
    {
      "epoch": 1.972,
      "grad_norm": 0.7842018604278564,
      "learning_rate": 4.202999999999999e-06,
      "loss": 0.9037,
      "step": 98600
    },
    {
      "epoch": 1.976,
      "grad_norm": 1.2158933877944946,
      "learning_rate": 3.6029999999999996e-06,
      "loss": 0.8601,
      "step": 98800
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6814543604850769,
      "learning_rate": 3.003e-06,
      "loss": 0.8889,
      "step": 99000
    },
    {
      "epoch": 1.984,
      "grad_norm": 1.3889033794403076,
      "learning_rate": 2.4029999999999997e-06,
      "loss": 0.8866,
      "step": 99200
    },
    {
      "epoch": 1.988,
      "grad_norm": 0.5688356161117554,
      "learning_rate": 1.8029999999999997e-06,
      "loss": 0.9154,
      "step": 99400
    },
    {
      "epoch": 1.992,
      "grad_norm": 1.2542932033538818,
      "learning_rate": 1.2029999999999997e-06,
      "loss": 0.8791,
      "step": 99600
    },
    {
      "epoch": 1.996,
      "grad_norm": 0.49539902806282043,
      "learning_rate": 6.03e-07,
      "loss": 0.842,
      "step": 99800
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6313440799713135,
      "learning_rate": 3e-09,
      "loss": 0.8501,
      "step": 100000
    }
  ],
  "logging_steps": 200,
  "max_steps": 100000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 765709987479552.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
